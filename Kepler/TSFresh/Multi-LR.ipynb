{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        labels = np.load(f).transpose()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(769, 12589)\n",
      "[[1 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "training_data_x = pickle.load(open(\"TS-Train.pkl\", \"rb\")).dropna(axis=1)\n",
    "training_data_x = preprocessing.normalize(training_data_x,norm='max', axis=0)\n",
    "training_data_x = training_data_x.transpose()\n",
    "print(training_data_x.shape)\n",
    "training_data_y = labels(\"../Labels-Train.npy\")\n",
    "print(training_data_y)\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.03\n",
    "epochs = 500\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 03:12:32.712045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 03:12:32.712663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 03:12:32.713103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 03:12:32.713576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 03:12:32.713983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-21 03:12:32.714305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 606 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training error= 0.044522736 Weights= [[ 5.01339557e-03  1.71137024e-02  2.23325472e-02 -7.04786414e-03\n",
      "  -1.28422189e-03  4.18380456e-04 -2.31175637e-03 -3.91539419e-03\n",
      "   2.71226210e-03  0.00000000e+00 -1.28422189e-03 -8.17341171e-03\n",
      "  -1.37613516e-03 -1.86205478e-04  3.30962153e-04 -1.78718846e-02\n",
      "  -6.13529934e-03 -1.17396191e-03 -2.31175637e-03 -2.60637645e-02\n",
      "  -7.80727118e-02  1.90359354e-02 -2.83349510e-02  6.65879948e-03\n",
      "   6.86497753e-03 -2.16727750e-03 -1.82716665e-03 -5.60510624e-03\n",
      "  -1.99350878e-03 -7.80419679e-03 -9.05426778e-03 -2.37163925e-03\n",
      "  -1.78080739e-03  8.17341171e-03 -1.13108251e-02  1.78207687e-04\n",
      "  -1.60381795e-04 -4.39446121e-05  2.58842076e-04  2.90711585e-04\n",
      "   3.44454194e-04  9.12157632e-03 -1.02082058e-03  0.00000000e+00\n",
      "  -4.55699973e-02  5.99909425e-02 -4.52779094e-03 -8.16772226e-03\n",
      "  -8.17341171e-03 -8.17341171e-03 -8.17341171e-03 -8.17341171e-03\n",
      "  -8.17341171e-03 -8.17341171e-03 -8.17341171e-03 -8.17341171e-03\n",
      "  -8.17341171e-03 -8.17341171e-03 -8.17341171e-03 -8.17341171e-03\n",
      "  -8.17341171e-03 -8.17341171e-03 -8.17341171e-03 -8.17341171e-03\n",
      "  -5.07455366e-03  2.82436665e-02  1.69220113e-03  1.58318467e-02\n",
      "   3.04485038e-02  4.95464774e-03  7.06917053e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.15236200e-01  6.57124743e-02\n",
      "   3.24984379e-02  1.28268674e-02  2.66569899e-04  9.27751971e-05\n",
      "  -9.47901281e-04 -3.18549434e-03 -8.17341171e-03  3.68648442e-03\n",
      "   3.85187077e-03  5.27841877e-03  7.73145910e-03  9.73999035e-03\n",
      "   1.01229995e-02  1.02439607e-02  1.00245513e-02  1.12336660e-02\n",
      "  -9.20818280e-03 -7.29053020e-02 -2.99013555e-02 -8.17341171e-03\n",
      "   3.68648442e-03 -8.95405828e-05 -2.97560851e-04  7.40399701e-04\n",
      "   7.70100800e-04 -1.35482856e-04  3.28905473e-04  5.25128271e-04\n",
      "  -3.76487369e-05 -2.11324953e-02  1.68173965e-02  8.31932202e-03\n",
      "   3.17119360e-02  4.97207865e-02  6.81531876e-02  1.74624473e-02\n",
      "   3.41721326e-02 -3.88511680e-02  1.91402491e-02  3.00355610e-02\n",
      "   1.05079543e-02 -2.42589060e-02 -4.27687727e-02 -2.86583621e-02\n",
      "   3.01178563e-02 -3.71642498e-04  5.76798059e-03  1.56749529e-03\n",
      "  -2.60012620e-03  5.30164875e-03  8.41531809e-03  2.11752928e-03\n",
      "  -2.17313506e-03  6.83134142e-03  6.62242435e-03  2.43709120e-03\n",
      "  -1.72046374e-03  8.55530798e-03  5.81322052e-03  2.12407717e-03\n",
      "  -1.23468286e-03  7.06730084e-03  5.27220126e-03  1.72933261e-03\n",
      "  -6.84427621e-04 -4.41006356e-04  4.81517660e-03  1.33989647e-03\n",
      "  -1.06728163e-04 -4.53385571e-03  4.35588975e-03  9.38833051e-04\n",
      "   4.00130753e-04 -4.10212530e-03  3.81806935e-03  5.16576285e-04\n",
      "   8.58190877e-04 -1.41747552e-03  3.08919069e-03  6.72399619e-05\n",
      "   1.28281256e-03  2.92809913e-03  1.88613520e-03 -4.12653288e-04\n",
      "   1.68514589e-03  2.74544419e-03  2.37463319e-05 -9.24536958e-04\n",
      "   2.07354897e-03  1.33144378e-03 -1.84620323e-03 -1.46748603e-03\n",
      "   2.45448295e-03 -3.86184634e-04 -3.27903521e-03 -2.03760574e-03\n",
      "   2.83303251e-03 -1.64932595e-03 -4.78720060e-03 -2.60087010e-03\n",
      "   3.21336417e-03 -1.50460016e-03 -6.12938590e-03 -3.15137510e-03\n",
      "   3.59896710e-03  1.78481173e-03  2.59684050e-03 -2.47299462e-03\n",
      "  -8.18284508e-03 -5.17314747e-02  3.69372182e-02 -3.82461911e-03\n",
      "  -9.36786830e-03  2.81139407e-02  2.76959082e-03 -2.02931855e-02\n",
      "  -6.63094549e-03  1.29066911e-02 -8.63990746e-03 -3.66082037e-04\n",
      "  -1.05857570e-02 -1.09971892e-02 -3.74582689e-03  1.11429115e-04\n",
      "  -2.06009112e-02 -1.73524059e-02 -2.33776364e-02  1.41766889e-03\n",
      "  -1.22110862e-02 -1.05463611e-02 -2.11771317e-02 -3.46009154e-04\n",
      "  -9.82451439e-03 -7.10815145e-03 -1.77327339e-02 -3.91539419e-03\n",
      "   1.75450896e-05 -2.31175637e-03  9.81258709e-05 -1.35038025e-03\n",
      "  -1.37743056e-02 -1.89007651e-02 -3.53034362e-02 -4.51894557e-05\n",
      "  -1.01723960e-02 -1.08684665e-02 -1.87001247e-02  8.34012695e-04\n",
      "  -7.52130477e-03 -5.59886964e-03 -1.47028454e-02 -4.70292475e-03\n",
      "   7.97587927e-05 -1.11972948e-03  1.24284052e-04 -1.33973852e-04\n",
      "  -3.24222981e-03 -1.08424155e-02 -1.87340416e-02  3.92190850e-04\n",
      "  -7.00092874e-03 -1.18003841e-02 -1.52846128e-02  6.08418559e-05\n",
      "   1.04434410e-04 -1.60904683e-03  1.32842921e-04  7.03187601e-04\n",
      "  -6.80992007e-03 -1.43055525e-02 -1.98151153e-02  3.94141214e-04\n",
      "   1.24335827e-04 -1.63637532e-03  1.41297482e-04  2.31300088e-04\n",
      "   1.19679644e-04 -1.05298066e-03  1.27409541e-04 -1.28422189e-03\n",
      "   1.99214127e-02 -1.79702528e-02  1.23676993e-02 -3.43436226e-02\n",
      "   4.96163927e-02 -2.61274390e-02  2.52544638e-02 -3.78660741e-03\n",
      "  -1.37212146e-02  3.02456673e-02 -2.90219113e-02  3.24722491e-02\n",
      "  -4.07634415e-02  2.33414304e-02 -2.01887898e-02  1.21040847e-02\n",
      "   5.58698736e-03 -1.00455629e-02  3.02059520e-02 -1.76970866e-02\n",
      "   1.58060845e-02 -1.18032852e-02  1.83398388e-02 -8.83045793e-03\n",
      "   2.69413530e-03  4.83574765e-03 -5.58782043e-03  8.22475273e-03\n",
      "  -8.42430722e-03  4.50477516e-03 -9.61314887e-03  5.22288540e-03\n",
      "  -2.76735576e-04 -1.54602202e-03  2.86298012e-03 -3.13307764e-03\n",
      "   1.39868411e-03 -2.27423548e-03  1.96144753e-03 -6.99409866e-04\n",
      "   7.38895964e-04 -1.15555900e-04 -1.34895308e-04  8.00679845e-04\n",
      "  -1.65133865e-03  4.02490055e-04 -3.41906823e-04  1.97597081e-03\n",
      "  -3.06349859e-04  3.11011623e-04  8.69879150e-04 -3.58376637e-05\n",
      "   1.39467156e-04  8.95042962e-04  1.53242156e-03 -2.33127121e-05\n",
      "  -3.19007755e-04  3.96843476e-04 -3.23199114e-04  2.04411990e-04\n",
      "   1.81950061e-04  5.26767457e-04  4.07293031e-04  1.33774034e-03\n",
      "  -1.10571367e-04  5.54678845e-04  1.94315135e-03  5.43948496e-04\n",
      "   7.45306141e-04 -2.62066078e-05 -9.20729828e-04 -2.75772298e-04\n",
      "  -4.85572964e-04  5.77879655e-05 -4.07677901e-04 -3.78185679e-04\n",
      "  -4.55936068e-04 -5.15166204e-04  4.74028784e-04 -2.41065471e-04\n",
      "   1.39843314e-05  7.90170510e-04 -2.08992395e-04  6.16145611e-04\n",
      "   8.88891227e-04  1.02081533e-04  7.21725752e-04  1.15466805e-03\n",
      "   3.27458838e-04  2.02840965e-04  5.19368099e-04  2.02176603e-03\n",
      "   1.55067246e-04  9.44624713e-04 -4.46504186e-04 -3.46441724e-04\n",
      "   1.37054501e-03  1.69060926e-03  2.86365921e-05  0.00000000e+00\n",
      "   6.58082892e-04 -4.24798578e-03  1.57691445e-03 -5.08096826e-04\n",
      "   2.01814575e-03 -4.98445751e-03  1.48489000e-03 -5.90432016e-03\n",
      "   3.51583061e-04 -5.29900845e-03 -7.53751083e-04  7.71186838e-04\n",
      "  -2.06200639e-03  4.95174900e-03 -6.41552173e-03  2.33925087e-03\n",
      "  -4.17345390e-03 -8.48074735e-04 -8.29181343e-04 -1.00211508e-03\n",
      "  -2.38762703e-04 -2.65927520e-03 -9.96411080e-04 -1.56000874e-03\n",
      "   2.07458716e-03 -2.30009924e-03  9.91576526e-05  4.85794211e-04\n",
      "   1.25399441e-04  7.85765063e-04 -2.94779637e-03  3.47130263e-04\n",
      "  -1.76083134e-03 -8.96342855e-04  5.82130509e-04 -9.24056687e-04\n",
      "   2.52600847e-04  1.55580943e-04  5.71069773e-04  2.68532109e-04\n",
      "  -2.42619208e-05 -1.88669423e-04  1.84266770e-04  2.40099791e-04\n",
      "   2.29006851e-04 -1.67919628e-04 -4.68362327e-04  1.21492412e-04\n",
      "  -3.93256960e-06  4.86940786e-04  1.76702320e-04  5.35855579e-05\n",
      "  -1.97548594e-04 -1.48214545e-04 -7.59114278e-04 -9.10649658e-04\n",
      "   3.35279561e-04  3.51995375e-04  2.02674433e-04 -5.50863100e-04\n",
      "  -2.04909622e-04  3.27980961e-04  6.81442209e-04 -4.54351044e-04\n",
      "  -1.03451987e-03  3.09210700e-05 -2.07298308e-05 -9.34465152e-06\n",
      "   3.85950261e-04  7.65122066e-04 -2.88770854e-04  6.26800465e-04\n",
      "  -1.43587677e-04  4.45663172e-04 -8.71736047e-05 -1.95661298e-04\n",
      "   1.59634277e-04 -6.28764028e-05 -3.71748756e-04  1.51400076e-04\n",
      "   1.26395506e-04 -2.02855808e-04  2.54869155e-05  1.49888519e-05\n",
      "  -7.11860950e-04  2.39765577e-04 -2.39311892e-04 -7.24888057e-04\n",
      "  -4.21565230e-04  3.23010870e-04 -9.32946743e-04  5.81898144e-04\n",
      "  -5.90661832e-04 -5.21763985e-04  1.11127039e-04  5.96310478e-04\n",
      "  -4.94473265e-04 -4.17933363e-04 -3.04729037e-04  3.66959651e-03\n",
      "   5.28374501e-03  3.90204927e-03  5.22130313e-06  6.68355357e-03\n",
      "   1.19400006e-02  5.97973960e-03 -4.11591725e-03 -1.55491699e-02\n",
      "  -1.71079151e-02 -7.69936945e-03  4.28303564e-03  1.02803055e-02\n",
      "   1.13275014e-02  5.95756155e-03  3.65870143e-03  3.31377523e-04\n",
      "  -2.80771125e-03 -2.22120201e-03  3.62083956e-04  2.91941804e-03\n",
      "   3.20990267e-03  7.90557358e-04 -3.57536541e-04 -1.75664946e-03\n",
      "  -1.88317627e-03 -5.25485841e-04 -2.13706226e-04  7.97555258e-04\n",
      "   7.45503698e-04  1.18437805e-03  2.14505894e-03  9.77470540e-04\n",
      "   1.01690018e-03  6.53329247e-04  1.03569485e-03  3.20843246e-04\n",
      "   1.36631436e-03  6.90200424e-04  5.27294003e-04  5.44862472e-04\n",
      "   1.82995107e-04  2.99433188e-04  3.13331024e-04  8.69958167e-05\n",
      "  -4.41446464e-04 -1.55558213e-04 -7.34247733e-04 -5.52504731e-04\n",
      "  -9.78347613e-04 -6.97301701e-04 -8.54125072e-04 -1.34306727e-03\n",
      "  -8.26397038e-04 -4.87802405e-04 -1.05874077e-03 -1.00462500e-03\n",
      "  -9.99598880e-04 -6.59064041e-04 -4.65666992e-04 -3.56436212e-04\n",
      "   5.72641729e-05 -2.97507417e-04 -3.59427868e-05 -1.72279673e-04\n",
      "   6.14629535e-05 -2.39309884e-04 -3.47310910e-04 -5.73390513e-04\n",
      "  -2.33356273e-04 -3.58149642e-04 -5.88209805e-05 -3.27826820e-05\n",
      "   2.53303529e-04  1.58598021e-04  3.42353102e-04  7.06206250e-04\n",
      "  -2.96015442e-05  4.31542692e-04  1.88603750e-04  1.68476327e-04\n",
      "   2.55583320e-04 -6.60577789e-05  3.08682676e-04  5.56057566e-05\n",
      "  -4.04770180e-05 -2.25801778e-04 -4.82033414e-04 -3.88898070e-06\n",
      "  -2.92203593e-04 -5.07181918e-04 -8.90604162e-04 -1.03180355e-03\n",
      "  -1.38089259e-03 -1.45280932e-03 -2.05319538e-03 -1.89342070e-03\n",
      "  -2.39704200e-03 -2.08032574e-03 -2.00861041e-03  4.36859280e-02\n",
      "   4.80174227e-03 -1.04360012e-02  2.35860329e-03 -6.95043337e-03\n",
      "   5.51737938e-03 -9.07054357e-03 -5.39998058e-04  1.57323033e-02\n",
      "   1.78501918e-03  4.45515737e-02 -2.22616829e-02  3.06783542e-02\n",
      "  -2.87712645e-02  1.69699378e-02 -1.72372162e-02  3.10570700e-03\n",
      "   1.82463210e-02 -7.15247495e-03  1.76486205e-02 -3.05465683e-02\n",
      "   2.89396588e-02 -1.46799823e-02  4.74471645e-03  2.70836381e-03\n",
      "   1.99153577e-03  2.12604422e-02 -1.22236181e-02  1.67496018e-02\n",
      "  -1.90840047e-02  1.56125855e-02 -5.31646749e-03  8.93041864e-03\n",
      "   4.38944995e-03 -1.03309965e-02  1.25980685e-02 -1.45241339e-02\n",
      "   1.49439024e-02 -1.44868121e-02  1.25929210e-02 -5.52154146e-03\n",
      "   1.57422479e-03  3.89342196e-03 -2.61490047e-03  2.07456225e-03\n",
      "  -1.49493739e-02  1.05167879e-02 -1.22504821e-03 -1.14687281e-02\n",
      "   1.15425864e-04  5.43515570e-03 -2.94900592e-03 -2.33210996e-03\n",
      "   2.62421346e-03 -4.39646561e-03  8.57616682e-03  2.04456807e-03\n",
      "   8.03860195e-04 -2.25245045e-03  1.04393822e-03  2.98352633e-03\n",
      "  -4.21837159e-03 -2.01440416e-03 -1.93871278e-03 -1.22959204e-02\n",
      "   7.02390308e-03  5.92985377e-03  4.47549438e-03  2.87467241e-03\n",
      "   2.43922672e-03 -1.16814161e-04  3.06043657e-04  1.17365667e-03\n",
      "  -2.98335007e-03  6.49347552e-04  4.59273899e-04  5.76924114e-03\n",
      "  -2.06349813e-03  8.39200523e-03  1.11562258e-03 -4.34785429e-03\n",
      "  -6.21549273e-03 -1.71640678e-03  6.49639033e-03 -1.02040125e-03\n",
      "   3.12551716e-03  5.23519050e-03  2.82203360e-03 -7.88008794e-03\n",
      "   4.82959440e-03 -4.02594730e-03  4.07083018e-04  7.21012196e-03\n",
      "  -4.62131295e-03  1.82949798e-03  1.54782564e-03 -4.79947031e-03\n",
      "   6.80068601e-03 -3.91769136e-04  4.64407215e-03  3.60411555e-02\n",
      "   8.00745189e-02 -8.95328596e-02 -6.72861785e-02 -6.27532427e-04\n",
      "  -3.98574310e-04  2.96476460e-03 -1.21170627e-02  0.00000000e+00\n",
      "  -5.48142847e-03 -7.20939040e-03  2.47236621e-03 -3.52108211e-04\n",
      "  -3.93942086e-04 -2.43547163e-03  1.03776762e-03  7.37337768e-03\n",
      "   3.95143824e-03 -2.32273713e-03  4.29121871e-03  1.06854420e-02\n",
      "   5.02949301e-03  1.82024352e-02 -7.51110613e-02 -4.00849106e-03\n",
      "   3.63189466e-02  3.25718336e-02 -6.29912305e-04  4.00390927e-05\n",
      "  -4.18039446e-04 -4.67387581e-05 -2.12150998e-03 -3.86006795e-05\n",
      "  -4.44670150e-04 -1.83501033e-04 -2.51974049e-03  1.03461761e-02\n",
      "  -1.07115170e-03 -3.53661344e-05 -3.96562828e-04 -2.15566746e-04\n",
      "  -3.52612144e-04  5.90630079e-05  9.20790626e-05 -3.87281587e-04\n",
      "  -3.44386121e-04  1.14561895e-04  1.55086024e-03 -1.66731037e-03\n",
      "   7.54666835e-05  1.07382830e-05 -3.24893103e-04 -6.31216075e-03\n",
      "  -2.43649539e-03  1.35035851e-04  1.75184757e-03 -8.98403302e-03\n",
      "  -1.02625682e-03  7.04574268e-05 -1.68262387e-03  3.15148546e-03\n",
      "  -7.29305996e-03  3.36394063e-04  1.69110820e-02 -5.28453514e-02\n",
      "  -1.68086246e-01  7.47953579e-02 -1.73147564e-05 -4.47310600e-03\n",
      "  -2.14067139e-02 -1.79584175e-02 -1.74997021e-02 -2.60780454e-02\n",
      "   9.84915271e-02  5.92921898e-02 -3.01569607e-02 -1.84777919e-02\n",
      "  -1.80945080e-02 -1.80182848e-02 -1.14259124e-02 -5.14257886e-02\n",
      "  -1.20681887e-02  1.81799084e-01  2.17503920e-01 -1.32666817e-02\n",
      "  -1.83121450e-02 -1.22544942e-02 -7.92886689e-03 -1.85828086e-03\n",
      "  -5.48142847e-03 -4.65430319e-03 -8.41647759e-03 -6.80896416e-02\n",
      "   1.15146553e-02  5.16173914e-02  9.83211845e-02  2.42132600e-02\n",
      "   1.27192801e-02 -2.86660041e-03 -9.49967839e-03  4.42006887e-04\n",
      "   1.06317056e-02  1.98762547e-02  2.70221941e-02  3.06966417e-02\n",
      "   3.13641578e-02]] Bias= [-0.00817341] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    acc_arr.append(accuracy(logistic_layer(np.dot(current_W,training_data_x) + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"Weights=\", session.run(W), \"Bias=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  46.8869123252859 %\n"
     ]
    }
   ],
   "source": [
    "test_x = pickle.load(open(\"TS-Test.pkl\", \"rb\")).dropna(axis=1)\n",
    "test_x = preprocessing.normalize(test_x, norm='max', axis=0)\n",
    "test_x = test_x.transpose()\n",
    "\n",
    "test_y = labels(\"../Labels-Test.npy\")\n",
    "\n",
    "predicted_y = np.dot(session.run(W), test_x) + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
