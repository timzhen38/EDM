{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        labels = np.load(f).transpose()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(769, 11021)\n",
      "[[0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "training_data_x = pickle.load(open(\"TS-Train.pkl\", \"rb\"))\n",
    "print(training_data_x.columns[training_data_x.isna().any()].tolist())\n",
    "training_data_x = training_data_x.dropna(axis=1)\n",
    "training_data_x = preprocessing.normalize(training_data_x,norm='max', axis=0)\n",
    "training_data_x = training_data_x.transpose()\n",
    "print(training_data_x.shape)\n",
    "training_data_y = labels(\"../Labels-Train.npy\")\n",
    "print(training_data_y)\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.03\n",
    "epochs = 500\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 02:42:04.435644: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training error= 0.044331145 Weights= [[ 5.36810420e-03  1.96958054e-02  2.27790363e-02 -7.78556755e-03\n",
      "  -1.08380034e-03  5.37627377e-04 -2.18205643e-03 -3.80541175e-03\n",
      "   3.87997925e-03  0.00000000e+00 -1.08380034e-03 -8.20909441e-03\n",
      "  -1.16759213e-03  8.42946029e-05  4.36961331e-04 -1.71008296e-02\n",
      "  -6.47426769e-03 -9.60198231e-04 -2.18205643e-03 -2.54432820e-02\n",
      "  -7.95905292e-02  1.78979468e-02 -2.71927789e-02  8.05565994e-03\n",
      "   8.25574528e-03 -1.84296258e-03 -1.46355527e-03 -4.84247552e-03\n",
      "  -7.24272977e-04 -7.63475290e-03 -8.98448471e-03 -3.14770523e-03\n",
      "  -1.70817412e-03  8.20909441e-03 -1.34884855e-02  1.81160765e-04\n",
      "  -1.70708503e-04 -4.40863150e-05  3.33903969e-04  3.79961275e-04\n",
      "   4.40937496e-04  9.16013774e-03 -9.92591609e-04  0.00000000e+00\n",
      "  -4.53061201e-02  5.82277924e-02 -4.24376968e-03 -8.20729695e-03\n",
      "  -8.20909441e-03 -8.20909441e-03 -8.20909441e-03 -8.20909441e-03\n",
      "  -8.20909441e-03 -8.20909441e-03 -8.20909441e-03 -8.20909441e-03\n",
      "  -8.20909441e-03 -8.20909441e-03 -8.20909441e-03 -8.20909441e-03\n",
      "  -8.20909441e-03 -8.20909441e-03 -8.20909441e-03 -8.20909441e-03\n",
      "  -4.98946290e-03  2.89358124e-02 -5.77960396e-04  1.45922052e-02\n",
      "   2.97077224e-02  4.93893027e-03  2.86711092e-05  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.15854174e-01  6.65513873e-02\n",
      "   3.30072530e-02  1.63614806e-02  5.53812133e-04  2.92934332e-04\n",
      "  -6.97594194e-04 -2.81231990e-03 -8.20909441e-03  3.80240101e-03\n",
      "   3.06228641e-03  4.36173147e-03  7.11428607e-03  9.98496637e-03\n",
      "   1.14016850e-02  1.18892798e-02  1.14666866e-02  1.24309277e-02\n",
      "  -9.84940026e-03 -7.32772872e-02 -2.89320387e-02 -8.20909441e-03\n",
      "   3.80240101e-03 -6.76670097e-05 -6.85484847e-04  2.43074587e-03\n",
      "   8.94317229e-04 -1.86384743e-04  3.30039795e-04  5.52156765e-04\n",
      "  -7.83163196e-05 -2.03346703e-02  1.70036834e-02  8.41356814e-03\n",
      "   3.16183902e-02  4.91525829e-02  6.66758269e-02  1.86988804e-02\n",
      "   3.51613499e-02 -3.94339301e-02  1.80643722e-02  2.95042023e-02\n",
      "   1.04575045e-02 -2.41017714e-02 -4.26715761e-02 -2.79162377e-02\n",
      "   3.05697937e-02 -8.74420803e-05  5.00508724e-03  1.27001165e-03\n",
      "  -2.81873648e-03  4.96505806e-03  7.74567295e-03  1.81247375e-03\n",
      "  -2.38345959e-03  6.23998418e-03  6.27797330e-03  2.12923973e-03\n",
      "  -1.92269939e-03  7.70107703e-03  5.64205367e-03  1.86423061e-03\n",
      "  -1.42915174e-03  7.75915617e-03  5.23912860e-03  1.50553905e-03\n",
      "  -8.65732378e-04 -5.56404470e-04  4.91277128e-03  1.13769679e-03\n",
      "  -2.61283625e-04 -3.99904465e-03  4.58380859e-03  7.49591796e-04\n",
      "   2.67049210e-04 -3.13226436e-03  4.17191256e-03  3.34779441e-04\n",
      "   7.42479460e-04  9.05865745e-05  3.54790152e-03 -1.10639281e-04\n",
      "   1.18113763e-03  3.90521088e-03  2.37230118e-03 -5.88597613e-04\n",
      "   1.59469957e-03  2.70740292e-03  3.57320037e-04 -1.09909638e-03\n",
      "   1.99186965e-03  8.51031276e-04 -1.97091117e-03 -1.63963262e-03\n",
      "   2.37933779e-03 -6.84687577e-04 -4.03149659e-03 -2.20443006e-03\n",
      "   2.76233698e-03 -1.38308108e-03 -5.79667697e-03 -2.75551900e-03\n",
      "   3.14510544e-03 -1.11752981e-03 -6.81207888e-03 -3.28554353e-03\n",
      "   3.53116472e-03  1.93460740e-03  2.53582373e-03 -2.67064897e-03\n",
      "  -8.27834941e-03 -5.08156791e-02  3.50279771e-02 -2.26039905e-03\n",
      "  -1.01188347e-02  2.92042755e-02  1.43883331e-03 -1.84947457e-02\n",
      "  -7.73576833e-03  1.33006386e-02 -8.96988530e-03 -1.17557764e-04\n",
      "  -1.11947889e-02 -1.17584048e-02 -4.24754666e-03 -3.63560662e-06\n",
      "  -2.04836819e-02 -1.71341784e-02 -2.33392101e-02  1.89210998e-03\n",
      "  -1.21562630e-02 -1.02440016e-02 -2.13257577e-02  1.02568441e-03\n",
      "  -9.75136273e-03 -6.85486384e-03 -1.78348850e-02 -3.80541175e-03\n",
      "   3.28597271e-05 -2.18205643e-03  1.11414178e-04 -8.25053314e-04\n",
      "  -1.37415901e-02 -1.97184719e-02 -3.60871777e-02  3.59486643e-04\n",
      "  -1.01850629e-02 -1.03748124e-02 -1.92896035e-02  1.25718175e-03\n",
      "  -7.35767698e-03 -5.25120087e-03 -1.45528875e-02 -4.50162869e-03\n",
      "   9.51389957e-05 -9.71519854e-04  1.37917479e-04 -1.34874808e-05\n",
      "  -4.72858129e-03 -1.25651667e-02 -1.80847999e-02  1.14178390e-03\n",
      "  -6.72234502e-03 -1.10406587e-02 -1.48298638e-02  2.82715104e-04\n",
      "   1.18812699e-04 -1.47086079e-03  1.45894315e-04  9.06201371e-04\n",
      "  -1.49314888e-02 -2.01673824e-02 -1.92709826e-02  6.63864776e-04\n",
      "   1.37713767e-04 -1.57014874e-03  1.54007925e-04  3.36225756e-04\n",
      "   1.30249493e-04 -9.92713147e-04  1.38044939e-04 -1.08380034e-03\n",
      "   1.97330751e-02 -1.81802008e-02  1.29007977e-02 -3.54196578e-02\n",
      "   4.96205315e-02 -2.55012251e-02  2.54957397e-02 -3.27481446e-03\n",
      "  -1.38344094e-02  2.98568234e-02 -2.89979260e-02  3.18327583e-02\n",
      "  -4.07642052e-02  3.26464958e-02 -1.99275874e-02  1.03208702e-02\n",
      "   5.84575906e-03 -9.28548723e-03  2.92569380e-02 -1.79040935e-02\n",
      "   1.64749976e-02 -1.15861325e-02  1.88367702e-02 -8.87992792e-03\n",
      "   2.68092053e-03  4.94422019e-03 -5.54814981e-03  8.13564379e-03\n",
      "  -7.98744522e-03  4.87499731e-03 -1.00943409e-02  5.37364464e-03\n",
      "   2.83195986e-05 -2.20974814e-03  3.05235665e-03 -3.64805292e-03\n",
      "   1.30587735e-03 -2.54257629e-03  2.13033939e-03 -7.33975903e-04\n",
      "   8.24793591e-04 -5.85858470e-05 -2.18225206e-04  7.95248838e-04\n",
      "  -1.37746008e-03  3.02376109e-04 -2.13198684e-04  2.29597744e-03\n",
      "  -3.40263621e-04  1.27088031e-04  7.16519309e-04  9.82828278e-05\n",
      "   1.01325561e-04  6.95469498e-04  1.33147638e-03 -2.16465312e-04\n",
      "   4.68331245e-06  2.40278299e-04 -2.54976883e-04  1.91951534e-04\n",
      "   2.22335802e-04  6.25544402e-04  3.67780274e-04  1.19250233e-03\n",
      "   3.68148139e-05  5.66766132e-04  1.85884046e-03  5.23089606e-04\n",
      "   1.06100820e-03  1.20008466e-04 -1.03324198e-03 -3.34588636e-04\n",
      "  -5.78948820e-04  1.38371732e-04 -1.78672315e-04 -5.78061736e-04\n",
      "  -4.27059596e-04 -3.09756113e-04  8.27737735e-04 -2.04604468e-04\n",
      "  -1.83067226e-04  8.52653233e-04 -2.27684461e-04  6.73916482e-04\n",
      "   1.11357449e-03  1.14981856e-04 -2.90482330e-05  1.09343207e-03\n",
      "   3.74534720e-05  6.80053257e-04  3.83269973e-04  3.35799600e-03\n",
      "  -3.90848756e-04  1.18177407e-03 -7.36539543e-04 -7.19616510e-05\n",
      "   1.45669386e-03  2.50054174e-03  9.91748766e-06  0.00000000e+00\n",
      "   5.00246999e-04 -4.10052901e-03  1.69215386e-03 -7.45908066e-04\n",
      "   2.20562029e-03 -4.84296354e-03  1.63069379e-03 -6.28166087e-03\n",
      "   6.52296178e-04 -4.62214369e-03 -7.52916152e-04  5.79875661e-04\n",
      "  -1.87552150e-03  4.52723075e-03 -7.08936853e-03  2.58101686e-03\n",
      "  -3.65380524e-03 -3.67474684e-04 -5.91557182e-04 -1.48515857e-03\n",
      "  -6.97885989e-04 -2.55465251e-03 -2.01123394e-03 -8.79256404e-04\n",
      "   2.96640233e-03 -1.38246291e-03  1.17605575e-03  9.65191284e-04\n",
      "  -5.82123816e-04  1.02021580e-03 -2.56873318e-03 -4.68547776e-04\n",
      "  -1.68439955e-03 -7.60260853e-04  2.72629812e-04 -8.61819426e-04\n",
      "   4.38387186e-04  3.51942319e-04  5.94337413e-04  4.57547372e-04\n",
      "  -1.54667243e-04 -2.63472775e-05  1.70149855e-04  1.95627406e-04\n",
      "   2.27338416e-04  4.80041563e-05 -1.49026950e-04  2.77644082e-04\n",
      "   2.57573920e-05  4.10355715e-04  1.40911157e-04  5.36682310e-05\n",
      "   4.73948012e-06 -2.76841311e-04 -8.06943164e-04 -4.39326133e-04\n",
      "   3.26783629e-04  4.12403228e-04 -7.60029870e-05 -4.19726042e-04\n",
      "   9.01543972e-05  4.67757549e-04  9.83566511e-04 -6.00738334e-04\n",
      "  -9.19748913e-04  1.26897939e-04  1.69870982e-04  1.59135088e-05\n",
      "   4.51551168e-04  8.41674220e-04 -5.14587096e-04  6.49882189e-04\n",
      "   1.90009145e-04  6.61739556e-04 -1.08966924e-04 -2.15267224e-04\n",
      "   2.24508301e-04 -2.52816390e-04 -3.22858046e-04  7.06233768e-05\n",
      "   9.37504083e-05 -4.16205788e-04 -6.46379995e-05 -1.95778939e-05\n",
      "  -7.15313712e-04  2.65312992e-04 -1.85174053e-04 -1.16895407e-03\n",
      "  -4.87162732e-04  4.88684047e-04 -1.06943678e-03  7.40957330e-04\n",
      "  -8.31138168e-04 -6.07913302e-04 -7.59779941e-05  1.06185465e-03\n",
      "  -3.94492905e-04 -3.29228671e-04 -3.62068939e-04  3.74388462e-03\n",
      "   5.52279688e-03  3.80583038e-03  3.51681520e-04  7.41203688e-03\n",
      "   1.14772022e-02  5.52371144e-03 -4.18433361e-03 -1.61999073e-02\n",
      "  -1.79503076e-02 -7.85748288e-03  4.20946116e-03  9.79652721e-03\n",
      "   1.13931373e-02  6.96081808e-03  3.75404721e-03  3.42946842e-05\n",
      "  -3.02136014e-03 -2.16152053e-03  8.63530673e-04  2.47092103e-03\n",
      "   3.69745214e-03  1.01827097e-03 -7.51380576e-05 -1.66537880e-03\n",
      "  -2.48112297e-03  2.84515001e-04 -3.00292566e-04  9.78184515e-04\n",
      "   1.17418997e-03  1.43481081e-03  2.73984857e-03  8.63268622e-04\n",
      "   9.58842691e-04  7.92429724e-04  1.29925890e-03  3.97672382e-04\n",
      "   1.56353251e-03  7.63984164e-04  6.36248267e-04  5.85183501e-04\n",
      "   2.26968856e-04  3.48367874e-04  3.76225071e-04  2.38203182e-04\n",
      "  -4.66615922e-04 -8.47305491e-05 -8.14555446e-04 -5.78284904e-04\n",
      "  -9.73715971e-04 -7.20928132e-04 -9.07418318e-04 -1.27647433e-03\n",
      "  -8.29433906e-04 -5.17696841e-04 -1.17066491e-03 -9.09740396e-04\n",
      "  -9.79955192e-04 -5.20127884e-04 -4.68713202e-04 -2.87688599e-04\n",
      "   3.45710898e-04 -1.32770336e-04 -2.87099956e-05 -7.03639744e-05\n",
      "   1.90493447e-05 -2.37953791e-04 -2.70391232e-04 -5.30754391e-04\n",
      "  -2.10436585e-04 -3.69860471e-04 -7.30789980e-05 -8.54206301e-05\n",
      "   3.19420098e-04  3.93935508e-04  2.77214916e-04  6.14849559e-04\n",
      "  -4.98150366e-05  4.82947216e-04  1.23421662e-04  1.95598972e-04\n",
      "   2.72657169e-04 -1.27931926e-04  3.81703168e-04  8.95038756e-05\n",
      "  -7.97295361e-05 -2.41868678e-04 -4.83789016e-04  1.04060789e-04\n",
      "  -2.46060517e-04 -7.38613016e-04 -7.38054572e-04 -1.02205598e-03\n",
      "  -1.23322057e-03 -1.17397867e-03 -2.45340727e-03 -2.20047939e-03\n",
      "  -2.38312129e-03 -2.27207737e-03 -2.24377308e-03  4.28690985e-02\n",
      "   5.14009455e-03 -9.58204176e-03  1.68510445e-03 -6.18742872e-03\n",
      "   4.26132139e-03 -5.25609916e-03 -2.63164937e-03  1.17975306e-02\n",
      "   1.71966129e-03  4.57838550e-02 -2.11771708e-02  3.03089935e-02\n",
      "  -3.01224664e-02  1.54991550e-02 -1.66078843e-02  4.21516784e-03\n",
      "   1.85508486e-02 -7.56463688e-03  1.73094049e-02 -3.13698798e-02\n",
      "   2.95415316e-02 -1.83617920e-02  4.27757483e-03  4.20183234e-04\n",
      "   1.58848357e-03  1.99167021e-02 -1.14582693e-02  1.87913105e-02\n",
      "  -1.55053856e-02  1.78252812e-02 -7.47716706e-03  6.58458611e-03\n",
      "   1.94793160e-03 -1.08554801e-02  9.72257648e-03 -1.35887638e-02\n",
      "   1.71848647e-02 -1.54290013e-02  1.02857016e-02 -1.00141903e-02\n",
      "   1.45688478e-03  5.52811474e-03  7.51850486e-04  1.15077768e-03\n",
      "  -1.41840009e-02  1.35466289e-02 -1.04564161e-03 -1.00460816e-02\n",
      "  -1.15434732e-03  5.72693208e-03 -3.45227914e-03 -4.13490226e-03\n",
      "   4.95249545e-03 -6.08576415e-03  1.13766799e-02  4.34277020e-03\n",
      "   5.17094799e-04 -3.03982501e-03  2.81035807e-03  3.47783975e-03\n",
      "  -4.58581420e-03 -1.34343957e-03 -1.78583592e-04 -1.44888666e-02\n",
      "   5.89810871e-03  2.96362536e-03  4.05984838e-03  4.53885458e-03\n",
      "   3.09048779e-03  7.23523544e-06  5.20238827e-04 -1.88180723e-03\n",
      "  -4.34887968e-03  2.83589237e-03  3.57428798e-03  5.55934757e-03\n",
      "  -3.39274947e-03  7.44091766e-03  3.18570691e-03 -4.88968706e-03\n",
      "  -8.61901324e-03 -1.06689974e-03  7.20841298e-03  2.01329414e-04\n",
      "   4.37493715e-03  8.79897084e-03  2.50270544e-03 -9.99624003e-03\n",
      "   4.67287330e-03 -4.69051395e-03  3.12252506e-03  6.66230870e-03\n",
      "  -3.69729032e-03  3.98457237e-03  4.57799848e-04 -2.50520557e-03\n",
      "   5.29151270e-03  4.37927753e-04  3.75579274e-03  3.67366932e-02\n",
      "   8.26707631e-02 -9.02378857e-02 -6.75006807e-02 -4.96372464e-04\n",
      "  -1.79870971e-04  3.58355208e-03 -1.23693272e-02  0.00000000e+00\n",
      "  -5.47523610e-03 -3.92935146e-03  1.77501142e-03 -9.29546950e-05\n",
      "  -4.93358064e-04 -2.24910234e-03  5.26214892e-04  6.79703290e-03\n",
      "   3.25329090e-03 -2.32496369e-03  3.73232248e-03  1.04925418e-02\n",
      "   4.47141053e-03  1.59235559e-02 -7.40101263e-02 -2.90206424e-03\n",
      "   3.70514505e-02  3.16143408e-02 -4.25993727e-04  2.39457717e-04\n",
      "  -1.64505051e-04 -4.57853566e-05 -1.94438710e-03  8.48747804e-05\n",
      "  -1.96090477e-04 -1.77617127e-04 -2.47124908e-03  9.57725197e-03\n",
      "  -8.47027113e-04 -1.45250879e-05 -4.84023127e-04 -2.91609205e-04\n",
      "  -4.41780110e-04  6.98364383e-05 -1.69505638e-05 -4.14094626e-04\n",
      "  -4.22091864e-04  1.25370221e-04  1.59329921e-03 -1.42836093e-03\n",
      "   8.77129860e-05  9.34115451e-06 -2.24490534e-04 -5.94559638e-03\n",
      "  -2.20806967e-03  1.43274709e-04  1.84482383e-03 -8.54229368e-03\n",
      "  -8.12351063e-04  9.02570682e-05 -1.62341620e-03  3.12565337e-03\n",
      "  -7.05940230e-03  3.72618524e-04  1.66702792e-02 -5.22156879e-02\n",
      "  -1.68276325e-01  7.41968304e-02 -3.99520068e-04 -4.30854782e-03\n",
      "  -2.13779956e-02 -1.78506710e-02 -1.72869787e-02 -2.57874690e-02\n",
      "   9.71961021e-02  5.90263829e-02 -2.93985773e-02 -1.79768465e-02\n",
      "  -1.81446541e-02 -1.83204357e-02 -9.97400843e-03 -5.00700660e-02\n",
      "  -1.13232043e-02  1.81098521e-01  2.16040134e-01 -1.69691592e-02\n",
      "  -1.82868857e-02 -1.29301390e-02 -8.41316953e-03 -2.05507199e-03\n",
      "  -5.47523610e-03 -4.59696539e-03 -8.52163415e-03 -6.77472726e-02\n",
      "   1.26717361e-02  5.24447300e-02  9.75115374e-02  2.37519331e-02\n",
      "   1.21931033e-02 -3.16230278e-03 -9.87408124e-03 -5.77371859e-04\n",
      "   1.06260385e-02  1.98544916e-02  2.71506365e-02  3.10442224e-02\n",
      "   3.17378566e-02]] Bias= [-0.00820907] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    acc_arr.append(accuracy(logistic_layer(np.dot(current_W,training_data_x) + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"Weights=\", session.run(W), \"Bias=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(769, 6)\n",
      "Accuracy percentage:  66.66666666666666 %\n"
     ]
    }
   ],
   "source": [
    "test_x = pickle.load(open(\"TS-Test.pkl\", \"rb\"))\n",
    "print(test_x.columns[test_x.isna().any()].tolist())\n",
    "test_x = test_x.dropna(axis=1)\n",
    "test_x = preprocessing.normalize(test_x, norm='max', axis=0)\n",
    "test_x = test_x.transpose()\n",
    "\n",
    "print(test_x.shape)\n",
    "test_y = labels(\"../Labels-Test.npy\")\n",
    "\n",
    "predicted_y = np.dot(session.run(W), test_x) + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
