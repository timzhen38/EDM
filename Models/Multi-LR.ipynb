{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-a151b39c-c9e0-4cf9-b1a3-9643935f87c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168366499,
    "source_hash": "cc523c23",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#normalize X values to help model converge\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve and format data - into labels and examples from the dataset\n",
    "def features_and_labels(filename):\n",
    "    data = np.matrix(pd.read_csv(filename).values)\n",
    "\n",
    "    #we need to transpose data sets to be compatable with our weight vectors\n",
    "    data_y = data[:, 0].transpose()\n",
    "    data_y-=1 #binaryization of the categorical data\n",
    "\n",
    "    data_x = data[:, 1:].transpose()\n",
    "    data_x = normalize(data_x)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_x, training_data_y = features_and_labels(\"../archive/exoTrain.csv\")\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 19:58:57.312857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:57.422057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:57.422761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:57.424289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-04 19:58:57.424749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:57.425808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:57.426540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:59.469463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:59.470509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:59.471290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-04 19:58:59.472055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, loss = 0.00363672, W = [[0. 0. 0. ... 0. 0. 0.]], b = [0.]\n",
      "t = 5, loss = 0.00356816, W = [[6.5006716e-05 5.8240956e-05 3.7853115e-05 ... 1.8715666e-05\n",
      "  3.0330835e-05 3.8086691e-05]], b = [0.00011102]\n",
      "t = 10, loss = 0.00352213, W = [[1.3444090e-04 1.1997453e-04 8.0120153e-05 ... 4.0680599e-05\n",
      "  6.3859370e-05 7.9387159e-05]], b = [0.00022158]\n",
      "t = 15, loss = 0.00348207, W = [[2.0233913e-04 1.7969179e-04 1.2091576e-04 ... 6.2688814e-05\n",
      "  9.7530792e-05 1.2125886e-04]], b = [0.00033039]\n",
      "t = 20, loss = 0.00344504, W = [[2.6741525e-04 2.3627648e-04 1.5902193e-04 ... 8.4209198e-05\n",
      "  1.3077853e-04 1.6306229e-04]], b = [0.00043767]\n",
      "t = 25, loss = 0.00341012, W = [[0.00032955 0.00028971 0.00019438 ... 0.00010513 0.00016345 0.00020453]], b = [0.00054352]\n",
      "t = 30, loss = 0.00337687, W = [[0.00038889 0.0003402  0.0002272  ... 0.00012544 0.00019551 0.00024554]], b = [0.00064801]\n",
      "t = 35, loss = 0.00334507, W = [[0.00044564 0.00038798 0.00025771 ... 0.00014518 0.00022697 0.00028605]], b = [0.00075116]\n",
      "t = 40, loss = 0.00331454, W = [[0.00049999 0.0004333  0.00028615 ... 0.00016438 0.00025786 0.00032605]], b = [0.00085299]\n",
      "t = 45, loss = 0.00328518, W = [[0.00055214 0.00047636 0.00031272 ... 0.00018306 0.00028821 0.00036554]], b = [0.0009535]\n",
      "Optimization Finished!\n",
      "Training error= 0.0032569065 W= [[0.00060225 0.00051736 0.0003376  ... 0.00020126 0.00031803 0.00040452]] b= [0.00105273] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "\n",
    "    if t % display_step == 0:\n",
    "        print(\"t = %g, loss = %g, W = %s, b = %s\" % (t, current_loss, str(current_W), str(current_b)))\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    acc_arr.append(accuracy(logistic_layer(current_W * training_data_x + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"W=\", session.run(W), \"b=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  60.526315789473685 %\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = features_and_labels(\"../archive/exoTest.csv\")\n",
    "\n",
    "predicted_y = session.run(W) * test_x + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
