{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-a151b39c-c9e0-4cf9-b1a3-9643935f87c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168366499,
    "source_hash": "cc523c23",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#normalize X values to help model converge\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve and format data - into labels and examples from the dataset\n",
    "def features_and_labels(filename):\n",
    "    data = np.matrix(pd.read_csv(filename).values)\n",
    "\n",
    "    #we need to transpose data sets to be compatable with our weight vectors\n",
    "    data_y = data[:, 0].transpose()\n",
    "    data_y-=1 #binaryization of the categorical data\n",
    "\n",
    "    data_x = data[:, 1:].transpose()\n",
    "    data_x = normalize(data_x)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_x, training_data_y = features_and_labels(\"../archive/exoTrain.csv\")\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.003\n",
    "epochs = 500\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 18:09:43.495711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.502553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.502871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.503570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-28 18:09:43.504080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.504461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.504858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.960754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.961365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.961790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-28 18:09:43.962151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 449 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, loss = 0.00363672, W = [[0. 0. 0. ... 0. 0. 0.]], b = [0.]\n",
      "t = 5, loss = 0.00356816, W = [[6.5006716e-05 5.8240956e-05 3.7853115e-05 ... 1.8715666e-05\n",
      "  3.0330835e-05 3.8086691e-05]], b = [0.00011102]\n",
      "t = 10, loss = 0.00352213, W = [[1.3444090e-04 1.1997453e-04 8.0120153e-05 ... 4.0680599e-05\n",
      "  6.3859370e-05 7.9387159e-05]], b = [0.00022158]\n",
      "t = 15, loss = 0.00348207, W = [[2.0233913e-04 1.7969179e-04 1.2091576e-04 ... 6.2688814e-05\n",
      "  9.7530792e-05 1.2125886e-04]], b = [0.00033039]\n",
      "t = 20, loss = 0.00344504, W = [[2.6741525e-04 2.3627648e-04 1.5902193e-04 ... 8.4209198e-05\n",
      "  1.3077853e-04 1.6306229e-04]], b = [0.00043767]\n",
      "t = 25, loss = 0.00341012, W = [[0.00032955 0.00028971 0.00019438 ... 0.00010513 0.00016345 0.00020453]], b = [0.00054352]\n",
      "t = 30, loss = 0.00337687, W = [[0.00038889 0.0003402  0.0002272  ... 0.00012544 0.00019551 0.00024554]], b = [0.00064801]\n",
      "t = 35, loss = 0.00334507, W = [[0.00044564 0.00038798 0.00025771 ... 0.00014518 0.00022697 0.00028605]], b = [0.00075116]\n",
      "t = 40, loss = 0.00331454, W = [[0.00049999 0.0004333  0.00028615 ... 0.00016438 0.00025786 0.00032605]], b = [0.00085299]\n",
      "t = 45, loss = 0.00328518, W = [[0.00055214 0.00047636 0.00031272 ... 0.00018306 0.00028821 0.00036554]], b = [0.0009535]\n",
      "t = 50, loss = 0.00325691, W = [[0.00060225 0.00051736 0.0003376  ... 0.00020126 0.00031803 0.00040452]], b = [0.00105273]\n",
      "t = 55, loss = 0.00322963, W = [[0.00065048 0.00055644 0.00036095 ... 0.00021899 0.00034734 0.00044301]], b = [0.00115068]\n",
      "t = 60, loss = 0.0032033, W = [[0.00069696 0.00059375 0.00038288 ... 0.00023628 0.00037616 0.00048102]], b = [0.00124736]\n",
      "t = 65, loss = 0.00317784, W = [[0.0007418  0.00062941 0.00040352 ... 0.00025313 0.0004045  0.00051854]], b = [0.0013428]\n",
      "t = 70, loss = 0.00315322, W = [[0.0007851  0.00066354 0.00042297 ... 0.00026956 0.00043238 0.0005556 ]], b = [0.00143701]\n",
      "t = 75, loss = 0.00312939, W = [[0.00082695 0.00069623 0.0004413  ... 0.00028559 0.0004598  0.0005922 ]], b = [0.00153001]\n",
      "t = 80, loss = 0.0031063, W = [[0.00086744 0.00072757 0.00045859 ... 0.00030121 0.00048678 0.00062835]], b = [0.00162181]\n",
      "t = 85, loss = 0.00308392, W = [[0.00090664 0.00075762 0.0004749  ... 0.00031644 0.00051333 0.00066406]], b = [0.00171245]\n",
      "t = 90, loss = 0.00306222, W = [[0.00094461 0.00078647 0.00049031 ... 0.0003313  0.00053946 0.00069935]], b = [0.00180193]\n",
      "t = 95, loss = 0.00304115, W = [[0.00098141 0.00081418 0.00050485 ... 0.00034578 0.00056517 0.00073421]], b = [0.00189027]\n",
      "t = 100, loss = 0.0030207, W = [[0.00101711 0.0008408  0.00051859 ... 0.0003599  0.00059048 0.00076866]], b = [0.0019775]\n",
      "t = 105, loss = 0.00300083, W = [[0.00105175 0.00086638 0.00053156 ... 0.00037367 0.0006154  0.00080271]], b = [0.00206363]\n",
      "t = 110, loss = 0.00298151, W = [[0.00108539 0.00089099 0.00054381 ... 0.00038709 0.00063993 0.00083637]], b = [0.00214868]\n",
      "t = 115, loss = 0.00296272, W = [[0.00111806 0.00091466 0.00055538 ... 0.00040017 0.00066408 0.00086965]], b = [0.00223266]\n",
      "t = 120, loss = 0.00294445, W = [[0.00114981 0.00093745 0.0005663  ... 0.00041292 0.00068787 0.00090255]], b = [0.00231561]\n",
      "t = 125, loss = 0.00292666, W = [[0.00118068 0.00095938 0.00057661 ... 0.00042535 0.00071129 0.00093509]], b = [0.00239752]\n",
      "t = 130, loss = 0.00290933, W = [[0.0012107  0.00098049 0.00058634 ... 0.00043747 0.00073437 0.00096727]], b = [0.00247843]\n",
      "t = 135, loss = 0.00289245, W = [[0.00123991 0.00100084 0.00059551 ... 0.00044928 0.00075711 0.00099911]], b = [0.00255835]\n",
      "t = 140, loss = 0.002876, W = [[0.00126835 0.00102043 0.00060416 ... 0.00046079 0.00077951 0.0010306 ]], b = [0.00263728]\n",
      "t = 145, loss = 0.00285996, W = [[0.00129603 0.00103932 0.00061231 ... 0.00047201 0.00080158 0.00106177]], b = [0.00271526]\n",
      "t = 150, loss = 0.00284432, W = [[0.00132301 0.00105753 0.00061999 ... 0.00048295 0.00082334 0.0010926 ]], b = [0.0027923]\n",
      "t = 155, loss = 0.00282906, W = [[0.00134929 0.00107508 0.00062722 ... 0.0004936  0.00084479 0.00112313]], b = [0.00286841]\n",
      "t = 160, loss = 0.00281416, W = [[0.00137491 0.001092   0.00063402 ... 0.00050399 0.00086593 0.00115334]], b = [0.00294361]\n",
      "t = 165, loss = 0.00279961, W = [[0.00139989 0.00110833 0.00064042 ... 0.00051411 0.00088678 0.00118325]], b = [0.00301791]\n",
      "t = 170, loss = 0.00278541, W = [[0.00142425 0.00112408 0.00064642 ... 0.00052397 0.00090733 0.00121286]], b = [0.00309133]\n",
      "t = 175, loss = 0.00277152, W = [[0.00144803 0.00113927 0.00065206 ... 0.00053358 0.0009276  0.00124218]], b = [0.00316388]\n",
      "t = 180, loss = 0.00275796, W = [[0.00147123 0.00115393 0.00065735 ... 0.00054295 0.0009476  0.00127122]], b = [0.00323557]\n",
      "t = 185, loss = 0.00274469, W = [[0.00149388 0.00116807 0.0006623  ... 0.00055207 0.00096733 0.00129998]], b = [0.00330643]\n",
      "t = 190, loss = 0.00273172, W = [[0.001516   0.00118173 0.00066693 ... 0.00056097 0.00098679 0.00132847]], b = [0.00337647]\n",
      "t = 195, loss = 0.00271903, W = [[0.00153761 0.00119491 0.00067126 ... 0.00056963 0.00100599 0.00135669]], b = [0.00344569]\n",
      "t = 200, loss = 0.00270661, W = [[0.00155872 0.00120763 0.0006753  ... 0.00057806 0.00102494 0.00138465]], b = [0.00351411]\n",
      "t = 205, loss = 0.00269446, W = [[0.00157935 0.00121991 0.00067906 ... 0.00058628 0.00104365 0.00141235]], b = [0.00358174]\n",
      "t = 210, loss = 0.00268256, W = [[0.00159952 0.00123177 0.00068256 ... 0.00059429 0.00106211 0.00143981]], b = [0.00364861]\n",
      "t = 215, loss = 0.0026709, W = [[0.00161923 0.00124322 0.00068581 ... 0.00060209 0.00108033 0.00146702]], b = [0.00371471]\n",
      "t = 220, loss = 0.00265949, W = [[0.00163852 0.00125428 0.00068881 ... 0.00060968 0.00109833 0.00149398]], b = [0.00378006]\n",
      "t = 225, loss = 0.0026483, W = [[0.00165738 0.00126496 0.00069159 ... 0.00061708 0.0011161  0.00152072]], b = [0.00384468]\n",
      "t = 230, loss = 0.00263734, W = [[0.00167584 0.00127526 0.00069416 ... 0.00062428 0.00113364 0.00154721]], b = [0.00390857]\n",
      "t = 235, loss = 0.00262659, W = [[0.0016939  0.00128522 0.00069651 ... 0.00063129 0.00115097 0.00157349]], b = [0.00397175]\n",
      "t = 240, loss = 0.00261605, W = [[0.00171158 0.00129483 0.00069867 ... 0.00063811 0.00116809 0.00159954]], b = [0.00403422]\n",
      "t = 245, loss = 0.00260571, W = [[0.00172889 0.00130412 0.00070063 ... 0.00064476 0.001185   0.00162536]], b = [0.00409601]\n",
      "t = 250, loss = 0.00259557, W = [[0.00174584 0.00131308 0.00070242 ... 0.00065122 0.0012017  0.00165098]], b = [0.00415711]\n",
      "t = 255, loss = 0.00258562, W = [[0.00176244 0.00132173 0.00070403 ... 0.00065752 0.0012182  0.00167638]], b = [0.00421755]\n",
      "t = 260, loss = 0.00257585, W = [[0.00177871 0.00133009 0.00070548 ... 0.00066364 0.00123451 0.00170158]], b = [0.00427733]\n",
      "t = 265, loss = 0.00256626, W = [[0.00179464 0.00133816 0.00070677 ... 0.0006696  0.00125063 0.00172657]], b = [0.00433645]\n",
      "t = 270, loss = 0.00255685, W = [[0.00181025 0.00134595 0.00070791 ... 0.00067539 0.00126656 0.00175136]], b = [0.00439494]\n",
      "t = 275, loss = 0.0025476, W = [[0.00182555 0.00135347 0.0007089  ... 0.00068103 0.00128231 0.00177595]], b = [0.0044528]\n",
      "t = 280, loss = 0.00253852, W = [[0.00184055 0.00136073 0.00070976 ... 0.00068651 0.00129787 0.00180035]], b = [0.00451004]\n",
      "t = 285, loss = 0.0025296, W = [[0.00185526 0.00136773 0.0007105  ... 0.00069184 0.00131326 0.00182456]], b = [0.00456668]\n",
      "t = 290, loss = 0.00252083, W = [[0.00186968 0.00137449 0.0007111  ... 0.00069702 0.00132847 0.00184858]], b = [0.00462271]\n",
      "t = 295, loss = 0.00251222, W = [[0.00188382 0.00138101 0.00071159 ... 0.00070206 0.00134352 0.00187241]], b = [0.00467815]\n",
      "t = 300, loss = 0.00250374, W = [[0.0018977  0.00138731 0.00071196 ... 0.00070695 0.0013584  0.00189607]], b = [0.00473301]\n",
      "t = 305, loss = 0.00249542, W = [[0.00191131 0.00139338 0.00071223 ... 0.00071171 0.00137311 0.00191955]], b = [0.00478729]\n",
      "t = 310, loss = 0.00248722, W = [[0.00192466 0.00139923 0.00071239 ... 0.00071632 0.00138766 0.00194285]], b = [0.00484101]\n",
      "t = 315, loss = 0.00247917, W = [[0.00193776 0.00140487 0.00071245 ... 0.00072081 0.00140206 0.00196597]], b = [0.00489418]\n",
      "t = 320, loss = 0.00247124, W = [[0.00195062 0.00141032 0.00071242 ... 0.00072516 0.0014163  0.00198893]], b = [0.0049468]\n",
      "t = 325, loss = 0.00246344, W = [[0.00196324 0.00141556 0.00071231 ... 0.00072939 0.00143038 0.00201172]], b = [0.00499887]\n",
      "t = 330, loss = 0.00245577, W = [[0.00197563 0.00142061 0.0007121  ... 0.00073349 0.00144432 0.00203435]], b = [0.00505042]\n",
      "t = 335, loss = 0.00244822, W = [[0.00198779 0.00142548 0.00071182 ... 0.00073747 0.00145812 0.00205681]], b = [0.00510144]\n",
      "t = 340, loss = 0.00244078, W = [[0.00199974 0.00143017 0.00071145 ... 0.00074133 0.00147176 0.00207911]], b = [0.00515195]\n",
      "t = 345, loss = 0.00243346, W = [[0.00201146 0.00143468 0.00071102 ... 0.00074507 0.00148527 0.00210125]], b = [0.00520195]\n",
      "t = 350, loss = 0.00242626, W = [[0.00202298 0.00143903 0.00071051 ... 0.00074869 0.00149864 0.00212324]], b = [0.00525145]\n",
      "t = 355, loss = 0.00241916, W = [[0.0020343  0.00144321 0.00070994 ... 0.0007522  0.00151187 0.00214508]], b = [0.00530045]\n",
      "t = 360, loss = 0.00241216, W = [[0.00204541 0.00144722 0.0007093  ... 0.00075561 0.00152497 0.00216676]], b = [0.00534897]\n",
      "t = 365, loss = 0.00240527, W = [[0.00205633 0.00145109 0.0007086  ... 0.0007589  0.00153793 0.0021883 ]], b = [0.00539701]\n",
      "t = 370, loss = 0.00239849, W = [[0.00206706 0.0014548  0.00070785 ... 0.00076209 0.00155077 0.00220968]], b = [0.00544458]\n",
      "t = 375, loss = 0.0023918, W = [[0.0020776  0.00145837 0.00070704 ... 0.00076517 0.00156348 0.00223093]], b = [0.00549168]\n",
      "t = 380, loss = 0.00238521, W = [[0.00208796 0.00146179 0.00070618 ... 0.00076815 0.00157606 0.00225203]], b = [0.00553833]\n",
      "t = 385, loss = 0.00237871, W = [[0.00209814 0.00146508 0.00070527 ... 0.00077104 0.00158852 0.00227299]], b = [0.00558452]\n",
      "t = 390, loss = 0.0023723, W = [[0.00210815 0.00146823 0.00070432 ... 0.00077382 0.00160086 0.00229381]], b = [0.00563027]\n",
      "t = 395, loss = 0.00236599, W = [[0.00211799 0.00147125 0.00070331 ... 0.00077651 0.00161308 0.00231449]], b = [0.00567558]\n",
      "t = 400, loss = 0.00235976, W = [[0.00212766 0.00147414 0.00070227 ... 0.0007791  0.00162518 0.00233504]], b = [0.00572045]\n",
      "t = 405, loss = 0.00235362, W = [[0.00213717 0.00147691 0.00070119 ... 0.00078161 0.00163717 0.00235545]], b = [0.0057649]\n",
      "t = 410, loss = 0.00234756, W = [[0.00214652 0.00147956 0.00070007 ... 0.00078402 0.00164905 0.00237574]], b = [0.00580893]\n",
      "t = 415, loss = 0.00234158, W = [[0.00215571 0.0014821  0.00069892 ... 0.00078634 0.00166081 0.00239589]], b = [0.00585254]\n",
      "t = 420, loss = 0.00233569, W = [[0.00216475 0.00148452 0.00069773 ... 0.00078858 0.00167246 0.00241591]], b = [0.00589575]\n",
      "t = 425, loss = 0.00232987, W = [[0.00217364 0.00148683 0.00069651 ... 0.00079073 0.00168401 0.00243581]], b = [0.00593855]\n",
      "t = 430, loss = 0.00232412, W = [[0.00218239 0.00148903 0.00069526 ... 0.0007928  0.00169545 0.00245558]], b = [0.00598095]\n",
      "t = 435, loss = 0.00231846, W = [[0.00219099 0.00149112 0.00069398 ... 0.00079478 0.00170679 0.00247523]], b = [0.00602296]\n",
      "t = 440, loss = 0.00231286, W = [[0.00219945 0.00149312 0.00069268 ... 0.00079669 0.00171802 0.00249476]], b = [0.00606459]\n",
      "t = 445, loss = 0.00230734, W = [[0.00220778 0.00149501 0.00069135 ... 0.00079851 0.00172915 0.00251417]], b = [0.00610583]\n",
      "t = 450, loss = 0.00230189, W = [[0.00221597 0.00149681 0.00069    ... 0.00080026 0.00174019 0.00253346]], b = [0.0061467]\n",
      "t = 455, loss = 0.00229651, W = [[0.00222403 0.00149852 0.00068862 ... 0.00080194 0.00175112 0.00255263]], b = [0.00618719]\n",
      "t = 460, loss = 0.00229119, W = [[0.00223196 0.00150013 0.00068723 ... 0.00080353 0.00176196 0.00257168]], b = [0.00622732]\n",
      "t = 465, loss = 0.00228594, W = [[0.00223976 0.00150165 0.00068582 ... 0.00080506 0.0017727  0.00259062]], b = [0.00626709]\n",
      "t = 470, loss = 0.00228076, W = [[0.00224743 0.00150309 0.00068439 ... 0.00080651 0.00178335 0.00260945]], b = [0.00630651]\n",
      "t = 475, loss = 0.00227564, W = [[0.00225499 0.00150444 0.00068294 ... 0.0008079  0.00179391 0.00262817]], b = [0.00634557]\n",
      "t = 480, loss = 0.00227058, W = [[0.00226243 0.00150572 0.00068148 ... 0.00080921 0.00180437 0.00264677]], b = [0.00638428]\n",
      "t = 485, loss = 0.00226558, W = [[0.00226975 0.00150691 0.00068001 ... 0.00081046 0.00181475 0.00266527]], b = [0.00642266]\n",
      "t = 490, loss = 0.00226064, W = [[0.00227695 0.00150802 0.00067852 ... 0.00081164 0.00182504 0.00268365]], b = [0.00646069]\n",
      "t = 495, loss = 0.00225576, W = [[0.00228404 0.00150906 0.00067702 ... 0.00081276 0.00183524 0.00270194]], b = [0.0064984]\n",
      "Optimization Finished!\n",
      "Training error= 0.0022509356 W= [[0.00229102 0.00151002 0.00067551 ... 0.00081381 0.00184536 0.00272011]] b= [0.00653577] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "\n",
    "    if t % display_step == 0:\n",
    "        print(\"t = %g, loss = %g, W = %s, b = %s\" % (t, current_loss, str(current_W), str(current_b)))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"W=\", session.run(W), \"b=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  52.63157894736842 %\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = features_and_labels(\"../archive/exoTest.csv\")\n",
    "\n",
    "predicted_y = session.run(W) * test_x + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
