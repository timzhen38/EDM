{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-a151b39c-c9e0-4cf9-b1a3-9643935f87c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168366499,
    "source_hash": "cc523c23",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#normalize X values to help model converge\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve and format data - into labels and examples from the dataset\n",
    "def features_and_labels(filename):\n",
    "    data = np.matrix(pd.read_csv(filename).values)\n",
    "\n",
    "    #we need to transpose data sets to be compatable with our weight vectors\n",
    "    data_y = data[:, 0].transpose()\n",
    "    data_y-=1 #binaryization of the categorical data\n",
    "\n",
    "    data_x = data[:, 1:].transpose()\n",
    "    data_x = normalize(data_x)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_x, training_data_y = features_and_labels(\"../archive/exoTrain.csv\")\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 21:09:14.866024: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-10-31 21:09:14.866069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tensorflow-2-6-20211029-181540): /proc/driver/nvidia/version does not exist\n",
      "2021-10-31 21:09:14.866645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, loss = 0.00363672, W = [[1.20844725e-05 1.08624172e-05 6.64995059e-06 ... 2.96250755e-06\n",
      "  5.31442720e-06 6.92352614e-06]], b = [2.1820326e-05]\n",
      "t = 5, loss = 0.00356816, W = [[7.8847261e-05 7.0592912e-05 4.6259072e-05 ... 2.3039685e-05\n",
      "  3.6960933e-05 4.6242436e-05]], b = [0.00013327]\n",
      "t = 10, loss = 0.00352213, W = [[1.4821738e-04 1.3214620e-04 8.8468623e-05 ... 4.5107339e-05\n",
      "  7.0611262e-05 8.7744906e-05]], b = [0.00024347]\n",
      "t = 15, loss = 0.00348207, W = [[2.1559105e-04 1.9126640e-04 1.2876095e-04 ... 6.7038280e-05\n",
      "  1.0422215e-04 1.2963693e-04]], b = [0.00035196]\n",
      "t = 20, loss = 0.00344504, W = [[2.8007483e-04 2.4720989e-04 1.6630910e-04 ... 8.8442190e-05\n",
      "  1.3736074e-04 1.7138754e-04]], b = [0.00045895]\n",
      "t = 25, loss = 0.00341012, W = [[0.00034164 0.00030004 0.00020114 ... 0.00010924 0.00016991 0.00021277]], b = [0.00056453]\n",
      "t = 30, loss = 0.00337687, W = [[0.00040044 0.00034996 0.00023348 ... 0.00012944 0.00020185 0.00025368]], b = [0.00066875]\n",
      "t = 35, loss = 0.00334507, W = [[0.00045669 0.00039724 0.00026356 ... 0.00014906 0.0002332  0.00029409]], b = [0.00077163]\n",
      "t = 40, loss = 0.00331454, W = [[0.00051059 0.00044209 0.00029161 ... 0.00016815 0.00026398 0.00033399]], b = [0.00087319]\n",
      "t = 45, loss = 0.00328518, W = [[0.00056232 0.00048472 0.00031783 ... 0.00018674 0.00029421 0.00037338]], b = [0.00097345]\n",
      "Optimization Finished!\n",
      "Training error= 0.003256906 W= [[0.00060225 0.00051736 0.0003376  ... 0.00020126 0.00031803 0.00040452]] b= [0.00105273] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "\n",
    "    if t % display_step == 0:\n",
    "        print(\"t = %g, loss = %g, W = %s, b = %s\" % (t, current_loss, str(current_W), str(current_b)))\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    acc_arr.append(accuracy(logistic_layer(current_W * training_data_x + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"W=\", session.run(W), \"b=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  60.526315789473685 %\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = features_and_labels(\"../archive/exoTest.csv\")\n",
    "\n",
    "predicted_y = session.run(W) * test_x + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
