{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9ab37e7-d8bb-46b1-9f33-199c4dc77fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "def find_tce(kepid, tce_plnt_num, filenames):\n",
    "    for filename in filenames:\n",
    "        for record in tf.compat.v1.python_io.tf_record_iterator(filename):\n",
    "            ex = tf.train.Example.FromString(record)\n",
    "            if (ex.features.feature[\"kepid\"].int64_list.value[0] == kepid and\n",
    "                ex.features.feature[\"tce_plnt_num\"].int64_list.value[0] == tce_plnt_num):\n",
    "                print(\"Found {}_{} in file {}\".format(kepid, tce_plnt_num, filename))\n",
    "                return ex\n",
    "    raise ValueError(\"{}_{} not found in files: {}\".format(kepid, tce_plnt_num, filenames))\n",
    "\n",
    "def getLocalView(kepid, dir):\n",
    "    # Find Kepler-90 g.\n",
    "    filenames = tf.io.gfile.glob(os.path.join(dir, \"*\"))\n",
    "    assert filenames, \"No files found in {}\".format(dir)\n",
    "    ex = find_tce(kepid, 1, filenames)\n",
    "\n",
    "    # Get the local view.\n",
    "    local_view = np.array(ex.features.feature[\"local_view\"].float_list.value)\n",
    "    #fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    #axes[1].plot(local_view, \".\")\n",
    "    #print(local_view.shape)\n",
    "    return local_view\n",
    "\n",
    "def downloadLC(target):\n",
    "    #search and download target light curve\n",
    "    try: \n",
    "        search_result = lk.search_lightcurve(target, author='Kepler', cadence='long')\n",
    "    except: \n",
    "        return \"Invalid Target\"\n",
    "\n",
    "    kep_id = search_result.target_name.data[0]\n",
    "    kep_id = str(kep_id.lstrip(\"kplr\"))\n",
    "    kep_id = int(kep_id.lstrip(\"0\"))\n",
    "\n",
    "    local_view = getLocalView(kep_id, \"EDM/Kepler/TFRecords\")\n",
    "    local_view_matrix = np.expand_dims(local_view,axis=0)\n",
    "    return local_view_matrix\n",
    "\n",
    "def downloadLC_kaggle(target):\n",
    "    search_result = lk.search_lightcurve(target, author='Kepler', cadence='long', quarter=3).download()\n",
    "    period = np.linspace(1, 20, 10000)\n",
    "    search_result = search_result.flatten().remove_outliers()\n",
    "    bls = search_result.to_periodogram(method='bls', period=period, frequency_factor=500);\n",
    "    \n",
    "    planet_b_period = bls.period_at_max_power\n",
    "    planet_b_t0 = bls.transit_time_at_max_power\n",
    "    #planet_b_dur = bls.duration_at_max_power\n",
    "    ax = search_result.fold(period=planet_b_period, epoch_time=planet_b_t0)\n",
    "    flux_arr = np.array(ax.flux)\n",
    "    flux_arr = flux_arr[~np.isnan(flux_arr)]\n",
    "    return flux_arr\n",
    "\n",
    "def getTPFimg(target):\n",
    "    try:\n",
    "        tpf = lk.search_targetpixelfile(target, author=\"Kepler\", cadence=\"long\")\n",
    "    except:\n",
    "        return \"Invalid Target\"\n",
    "    tpf = tpf.download()\n",
    "    tpf.plot()\n",
    "    tmpfile = BytesIO()\n",
    "    plt.savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue())\n",
    "    return str(encoded)\n",
    "\n",
    "def getLCimg(target):\n",
    "    try:\n",
    "        lc = lk.search_lightcurve(target, author='Kepler', cadence='long')\n",
    "    except:\n",
    "        return \"Invalid Target\"\n",
    "    lc = lc.download()\n",
    "    lc.plot()\n",
    "    tmpfile = BytesIO()\n",
    "    plt.savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue())\n",
    "    return str(encoded)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d103a214-ead3-4d1b-98df-d91ceef6d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from numpy import exp\n",
    "import lightkurve\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "#import inputlightcurve\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters, EfficientFCParameters\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def tobool(prob):\n",
    "    if(prob<.5):                            #**might be .625/.75 instead of .5**\n",
    "        return \"false\"\n",
    "    else:\n",
    "        return \"true\"\n",
    "\n",
    "def contains(modelsList, model):\n",
    "    for m in modelsList:\n",
    "        if m == model:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y))\n",
    "    y = y.ravel()\n",
    "    return y\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    data = (data - mean) / std\n",
    "    return data\n",
    "\n",
    "def light_curve_to_matrix_kaggle_lightkurve(lc):\n",
    "    inputLC = downloadLC(lc)\n",
    "    flux_copy = np.array(inputLC[0])\n",
    "    amt_pad = 3197-(len(inputLC[0])%3197)                                              #amount of medians to pad the last row of dataframe\n",
    "    flux_median = np.full(shape=amt_pad, fill_value=np.median(np.array(inputLC[0])))   #array of medians to pad the last row to reach a factor of 3197\n",
    "    flux_copy = np.append(flux_copy, flux_median)\n",
    "    final_matrix = np.reshape(flux_copy, (len(flux_copy)//3197,3197))\n",
    "    normalized_matrix = normalize(final_matrix)\n",
    "    return normalized_matrix\n",
    "\n",
    "def light_curve_to_matrix_kepler_tsfresh(lc):\n",
    "    inputLC = downloadLC(lc)\n",
    "    #print(np.sum(np.isnan(np.array(inputLC))))\n",
    "    matrix = pd.DataFrame({\"id\" : np.zeros(len(inputLC[0]), dtype=int),\n",
    "                \"time\" : list(range(0, len(inputLC[0]))),\n",
    "                \"flux\" : inputLC[0]})               #convert from big endian\n",
    "    #print(matrix)\n",
    "    extracted_features = extract_features(matrix, column_id= \"id\", column_sort= \"time\", \n",
    "                                      column_value= \"flux\", \n",
    "                                      default_fc_parameters= EfficientFCParameters())\n",
    "    #print(np.sum(np.isnan(np.array(extracted_features))))\n",
    "    extracted_features.dropna(axis=1, inplace=True)  #dropped the nan column\n",
    "    #print(extracted_features)\n",
    "    normalized_matrix = preprocessing.normalize(extracted_features,norm='max', axis=0)\n",
    "    #print(normalized_matrix)\n",
    "    return normalized_matrix\n",
    "\n",
    "def light_curve_to_matrix_kaggle_tsfresh(lc):\n",
    "    inputLC = downloadLC_kaggle(lc)\n",
    "    #print(np.sum(np.isnan(np.array(inputLC))))\n",
    "    matrix = pd.DataFrame({\"id\" : np.zeros(len(inputLC), dtype=int),\n",
    "                \"time\" : list(range(0, len(inputLC))),\n",
    "                \"flux\" : inputLC.byteswap().newbyteorder()})               #convert from big endian\n",
    "    #print(matrix)\n",
    "    extracted_features = extract_features(matrix, column_id= \"id\", column_sort= \"time\", \n",
    "                                      column_value= \"flux\", \n",
    "                                      default_fc_parameters= EfficientFCParameters())\n",
    "    #print(np.sum(np.isnan(np.array(extracted_features))))\n",
    "    extracted_features.dropna(axis=1, inplace=True)  #dropped the nan column\n",
    "    #print(extracted_features)\n",
    "    normalized_matrix = preprocessing.normalize(extracted_features,norm='max', axis=0)\n",
    "    #print(normalized_matrix)\n",
    "    return normalized_matrix\n",
    "\n",
    "#still gotta work on func for kepler data and lightkurve\n",
    "\n",
    "def predict(input, training_data, processing, models):\n",
    "    results = {}\n",
    "    \n",
    "\n",
    "    #kaggle and tsfresh\n",
    "    if training_data == \"kaggle\":\n",
    "        if processing == \"tsfresh\":\n",
    "            inputLC_kaggle_tsfresh = light_curve_to_matrix_kaggle_tsfresh(input)\n",
    "            inputLC_kaggle_tsfresh_keras = np.expand_dims(inputLC_kaggle_tsfresh, -1) \n",
    "            #RNN\n",
    "            if contains(models, \"rnn\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/TSFresh/keras-models/KerasRNN\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_tsfresh_keras)\n",
    "                results[\"RNN\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            #LSTM\n",
    "            if contains(models, \"lstm\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/TSFresh/keras-models/KerasLSTM\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_tsfresh_keras)\n",
    "                results[\"LSTM\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            \n",
    "            #GRU\n",
    "            if contains(models, \"gru\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/TSFresh/keras-models/KerasGRU\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_tsfresh_keras)\n",
    "                results[\"GRU\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            #Logistic Regression\n",
    "            if contains(models, \"lr\"):\n",
    "                with open('EDM/Kaggle/TSFresh/tf-models/multi-lr.npy', 'rb') as f:\n",
    "                    W = np.load(f)\n",
    "                    b = np.load(f)\n",
    "                predicted_y = W * inputLC_kaggle_tsfresh + b\n",
    "                predicted_y = logistic_layer(predicted_y)\n",
    "                probability = np.max(predicted_y)\n",
    "                results[\"LR\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            \n",
    "            #Decision Tree & Random Forest\n",
    "            if contains(models, \"rf\"):\n",
    "                with open('EDM/Kaggle/TSFresh/tf-models/decision-tree.pkl', 'rb') as f:\n",
    "                    dt = pickle.load(f)\n",
    "                probability = dt.predict(inputLC_kaggle_tsfresh)\n",
    "                results[\"DT\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "                with open('EDM/Kaggle/TSFresh/tf-models/random-forest.pkl', 'rb') as f:\n",
    "                    rf = pickle.load(f)\n",
    "                probability = rf.predict(inputLC_kaggle_tsfresh)\n",
    "                results[\"RF\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "    \n",
    "    #kaggle and lightkurve\n",
    "    if training_data == \"kaggle\":\n",
    "        if processing == \"lightkurve\":\n",
    "            inputLC_kaggle_lightkurve = light_curve_to_matrix_kaggle_lightkurve(input)\n",
    "            inputLC_kaggle_lightkurve_keras = np.expand_dims(inputLC_kaggle_lightkurve, -1) \n",
    "            #RNN\n",
    "            if contains(models, \"rnn\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/Regular/keras-models/KerasRNN\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_lightkurve_keras)\n",
    "                results[\"RNN\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            #LSTM\n",
    "            if contains(models, \"lstm\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/Regular/keras-models/KerasLSTM\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_lightkurve_keras)\n",
    "                results[\"LSTM\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            \n",
    "            #GRU\n",
    "            if contains(models, \"gru\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kaggle/Regular/keras-models/KerasGRU\")\n",
    "                probability = reconstructed_model.predict(inputLC_kaggle_lightkurve_keras)\n",
    "                results[\"GRU\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            #Logistic Regression\n",
    "            if contains(models, \"lr\"):\n",
    "                with open('EDM/Kaggle/Regular/tf-models/multi-lr.npy', 'rb') as f:\n",
    "                    W = np.load(f)\n",
    "                    b = np.load(f)\n",
    "                predicted_y = W * inputLC_kaggle_lightkurve + b\n",
    "                predicted_y = logistic_layer(predicted_y)\n",
    "                probability = np.max(predicted_y)\n",
    "                results[\"LR\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            \n",
    "            #Decision Tree & Random Forest\n",
    "            if contains(models, \"rf\"):\n",
    "                with open('EDM/Kaggle/Regular/tf-models/decision-tree.pkl', 'rb') as f:\n",
    "                    dt = pickle.load(f)\n",
    "                probability = dt.predict(inputLC_kaggle_lightkurve)\n",
    "                results[\"DT\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "                with open('EDM/Kaggle/Regular/tf-models/random-forest.pkl', 'rb') as f:\n",
    "                    rf = pickle.load(f)\n",
    "                probability = rf.predict(inputLC_kaggle_lightkurve)\n",
    "                results[\"RF\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "    #kepler and tsfresh\n",
    "    if training_data == \"kepler\":\n",
    "        if processing == \"tsfresh\":\n",
    "            inputLC_kepler_tsfresh = light_curve_to_matrix_kepler_tsfresh(input)\n",
    "            inputLC_kepler_tsfresh_keras = np.expand_dims(inputLC_kepler_tsfresh, -1) \n",
    "            #RNN\n",
    "            if contains(models, \"rnn\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/TSFresh/keras-models/KerasRNN\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_tsfresh_keras)\n",
    "                results[\"RNN\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            #LSTM\n",
    "            if contains(models, \"lstm\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/TSFresh/keras-models/KerasLSTM\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_tsfresh_keras)\n",
    "                results[\"LSTM\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            \n",
    "            #GRU\n",
    "            if contains(models, \"gru\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/TSFresh/keras-models/KerasGRU\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_tsfresh_keras)\n",
    "                results[\"GRU\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            #Logistic Regression\n",
    "            if contains(models, \"lr\"):\n",
    "                with open('EDM/Kepler/TSFresh/tf-models/multi-lr.npy', 'rb') as f:\n",
    "                    W = np.load(f)\n",
    "                    b = np.load(f)\n",
    "                predicted_y = W * inputLC_kepler_tsfresh + b\n",
    "                predicted_y = logistic_layer(predicted_y)\n",
    "                probability = np.max(predicted_y)\n",
    "                results[\"LR\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            \n",
    "            #Decision Tree & Random Forest\n",
    "            if contains(models, \"rf\"):\n",
    "                with open('EDM/Kepler/TSFresh/tf-models/decision-tree.pkl', 'rb') as f:\n",
    "                    dt = pickle.load(f)\n",
    "                probability = dt.predict(inputLC_kepler_tsfresh)\n",
    "                results[\"DT\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "                with open('EDM/Kepler/TSFresh/tf-models/random-forest.pkl', 'rb') as f:\n",
    "                    rf = pickle.load(f)\n",
    "                probability = rf.predict(inputLC_kepler_tsfresh)\n",
    "                results[\"RF\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "    #kepler and lightkurve\n",
    "    if training_data == \"kepler\":\n",
    "        if processing == \"lightkurve\":\n",
    "            inputLC_kepler_lightkurve = downloadLC(input)\n",
    "            inputLC_kepler_lightkurve_keras = np.expand_dims(inputLC_kepler_lightkurve, -1)\n",
    "            print(inputLC_kepler_lightkurve_keras.shape)\n",
    "            #RNN\n",
    "            if contains(models, \"rnn\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/Regular/keras-models/KerasRNN\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_lightkurve_keras)\n",
    "                results[\"RNN\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            #LSTM\n",
    "            if contains(models, \"lstm\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/Regular/keras-models/KerasLSTM\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_lightkurve_keras)\n",
    "                results[\"LSTM\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "            \n",
    "            #GRU\n",
    "            if contains(models, \"gru\"):\n",
    "                reconstructed_model = keras.models.load_model(\"EDM/Kepler/Regular/keras-models/KerasGRU\")\n",
    "                probability = reconstructed_model.predict(inputLC_kepler_lightkurve_keras)\n",
    "                results[\"GRU\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            #Logistic Regression\n",
    "            if contains(models, \"lr\"):\n",
    "                with open('EDM/Kepler/Regular/tf-models/multi-lr.npy', 'rb') as f:\n",
    "                    W = np.load(f)\n",
    "                    b = np.load(f)\n",
    "                predicted_y = W * inputLC_kepler_lightkurve + b\n",
    "                predicted_y = logistic_layer(predicted_y)\n",
    "                probability = np.max(predicted_y)\n",
    "                results[\"LR\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "            \n",
    "            #Decision Tree & Random Forest\n",
    "            if contains(models, \"rf\"):\n",
    "                with open('EDM/Kepler/Regular/tf-models/decision-tree.pkl', 'rb') as f:\n",
    "                    dt = pickle.load(f)\n",
    "                probability = dt.predict(inputLC_kepler_lightkurve)\n",
    "                results[\"DT\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "\n",
    "                with open('EDM/Kepler/Regular/tf-models/random-forest.pkl', 'rb') as f:\n",
    "                    rf = pickle.load(f)\n",
    "                probability = rf.predict(inputLC_kepler_lightkurve)\n",
    "                results[\"RF\"] = {\"Probability\" : probability, \"Classification\" : tobool(probability)}\n",
    "    return results\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16436f6f-3f0f-4a7b-a524-bf4206f2fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': {'RNN': {'Probability': array([[0.50915194]], dtype=float32), 'Classification': 'true'}, 'LSTM': {'Probability': array([[0.29465556]], dtype=float32), 'Classification': 'false'}, 'GRU': {'Probability': array([[0.48944402]], dtype=float32), 'Classification': 'false'}}}\n"
     ]
    }
   ],
   "source": [
    "list_of_models = [\"rnn\",\"lstm\",\"gru\"]\n",
    "dict_data = {\n",
    "    #\"targetpixelfile\" : getTPFimg(\"KIC 3733346\"),\n",
    "    #\"lightcurve\" : getLCimg(\"KIC 3733346\"),\n",
    "    \"results\" : predict(\"KIC 3733346\", \"kaggle\", \"tsfresh\", list_of_models)\n",
    "    }\n",
    "print(dict_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de408d55-226a-4759-af30-7ccddd2ba27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4134,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test = downloadLC_kaggle(\"KIC 3733346\")\n",
    "test_arr = test\n",
    "print(test_arr.shape)\n",
    "print(np.sum(np.isnan(np.array(test_arr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d2f40-ecc5-43e9-bbfb-f504832de383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
